accidents_police <- accidents %>%
filter(police == "Yes")
accidents_no_police <- accidents %>%
filter(police == "No")
#plotting
a <- ggplot(data = accidents_police, aes(x = speed_limit)) +
geom_density(fill = "red", alpha = 0.4
) +
geom_density(data = accidents_no_police, fill = "blue", alpha = 0.4
) +
facet_wrap(~urban_rural, nrow = 2)
a
#Note: the density curve for accidents across speed limits is real interesting/funk and bears some investigation
#Pros:
#allows us to see if there is a trend relating speed limit to accident density (there is, a weird one)
#allows us to see if  there is a difference in police responsiveness relating to speed limit
#compares these trends across urban and rural environments
#cons
#hard to glean precise understanding of trends, you i=only really see the shape
#doesn't control for conditions or vehicle count, which feel relavent
accidents <- accidents %>%
filter(vehicles < 6)
ggplot(data = accidents, aes(x = vehicles, fill = police)) +
geom_bar()
#how do I choose what color is associated with what??
#pros
#both b & c give a sense of the relative number of crashes across vehicle count
#shows trend of police response relative to vehicles involved
#cons
#would need to make the bars equally sized to understand the true relative rates
accidents <- accidents %>%
filter(vehicles < 6)
# Convert urban_rural to factor
#ChatGPT explained this, I was already trying to find a way using mutate() to reclass urban_rural as categorical with only two categories
accidents$urban_rural <- factor(accidents$urban_rural)
ggplot(data = accidents, aes(x = vehicles, fill = urban_rural)) +
geom_bar()
#still don't know what the third category in urban_rural is
#pros
#both b & c give a sense of the relative number of crashes across vehicle count
#shows trend of urban/rural environment relative to vehicles involved
#cons
#would need to make the bars equally sized to understand the true relative rates
accidents$urban_rural <- factor(accidents$urban_rural)
ggplot(data = accidents, aes(x = urban_rural, fill = police)) +
geom_bar()
#pros
#both b & c give a sense of the relative number of crashes across vehicle count
#shows trend of police response relative to urban/rural environment
#cons
#would need to make the bars equally sized to understand the true relative rates
#I'd like to do this with one of these but I'm not sure which
# Creating the dataframe with the correct dimensions
animal_data <- data.frame(
theanimalsweightisthisnumber = c(runif(3), NA),
y = c("cat", "mouse", "dog", "rat")
)
# Mutating the dataframe to add 'animal_weight' column
animal_data <- animal_data %>%
mutate(animal_weight = theanimalsweightisthisnumber) %>%
select(-theanimalsweightisthisnumber)  # Remove the column
view(animal_data)
# Calculating median, mean, and variance
median_val <- median(animal_data$animal_weight, na.rm = TRUE)
mean_val <- mean(animal_data$animal_weight, na.rm = TRUE)
variance_val <- var(animal_data$animal_weight, na.rm = TRUE)
# Printing the results
cat("Median:", median_val, "\n")
cat("Mean:", mean_val, "\n")
cat("Variance:", variance_val, "\n")
# Plotting the data
ggplot(animal_data, aes(y = animal_weight, x = y)) +
geom_col() +
scale_y_continuous()
thing.132232=data.frame(theanimalsweightisthisnumber=c(runif(3),NA),y=c("cat","mouse","dog","rat"))
median(thing.132232$theanimalsweightisthisnumber, TRUE);mean(thing.132232$theanimalsweightisthisnumber, 0 , TRUE); var(thing.132232$theanimalsweightisthisnumber, NULL, TRUE)
ggplot(thing.132232, aes(y=theanimalsweightisthisnumber,x=y))+geom_col()+scale_y_continuous()
# Turning the elements_by_episode df into a tibble
elem <- tibble::as_tibble(elements_by_episode)[,-2][,-1]
# Taking the sums of all columns in the tibble
sums <- colSums(elem)
# Creating a data frame from the sums
sums_bob_ross <- as.data.frame(sums, row.names = NULL, optional = FALSE)
names(sums_bob_ross) <- "sums"  # Naming the column
# Filtering out rows with a 'sums' value less than 5
sums_bob_ross <- filter(sums_bob_ross, sums > 5) %>% mutate(prop = (sums / 381)*100)
ggplot(as.data.frame(t(as.matrix(sums_bob_ross)), aes(x = prop)) + geom_bar()
# Plotting
ggplot(sums_bob_ross, aes(x = factor(1), y = sums)) +
ggplot(as.data.frame(t(as.matrix(sums_bob_ross)), aes(x = prop)) + geom_bar()
ggplot(as.data.frame(t(as.matrix(sums_bob_ross)), aes(x = prop)) + geom_bar()
ggplot(data = as.data.frame(t(as.matrix(sums_bob_ross))), aes(x = prop)) + geom_bar()
as.data.frame(t(as.matrix(sums_bob_ross))
as.data.frame(t(as.matrix(sums_bob_ross)))
df_br <- as.data.frame(t(as.matrix(sums_bob_ross)))
View(df_br)
?ggplot
?geom_bar
ggplot(data = df_br, x = prop) + geom_bar()
ggplot(data = df_br, x = prop) + geom_bar()
ggplot(data = df_br, x = prop, y = BARN) + geom_bar()
ggplot(data = df_br, x = prop) + geom_bar()
ggplot(data = df_br, x = BARN) + geom_bar()
ggplot(data = df_br, y = BARN) + geom_bar()
ggplot(data = df_br, y = sums) + geom_bar()
ggplot(data = sums_bob_ross, y = sums) + geom_bar()
ggplot(data = df_br, y = sums) + geom_col()
ggplot(data = df_br, x = sums) + geom_col()
ggplot(data = df_br, aes(x= prop)) + geom_col()
ggplot(data = df_br, aes(x= sums)) + geom_col()
ggplot(data = sums_bob_ross, aes(x= sums)) + geom_col()
ggplot(data = sums_bob_ross, aes(y= sums)) + geom_col()
# Get the Data
# Read in with tidytuesdayR package
# Install from CRAN via: install.packages("tidytuesdayR")
# This loads the readme and all the datasets for the week of interest
library(tidytuesdayR)
tuesdata <- tidytuesdayR::tt_load('2022-07-05') # this could take a minute
rent <- tuesdata$rent
view(rent)
view(tuesdata)
data(tuesdata)
view(tuesdata)
# Do not modify this chunk.
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
# Creating a function to delete rows with a certain minimum number of NA's
delete.na <- function(DF, n = 0) {
DF[rowSums(is.na(DF)) <= n, ]
}
# Assuming 'covid_survey' is your data frame
covid_cleaned <- delete.na(covid_survey, 12)
# Do not modify this chunk.
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
# Put all necessary libraries here
library(tidyverse)
library(ggplot2)
library(tidytuesdayR)
library(readr)
library(datapasta)
library(dplyr)
#using the libraries
covid_survey <- read_csv("C:/Users/agjjo/OneDrive/Documents/GitHub/math241/labs/lab04/data/covid-survey.csv")
#View(covid_survey)
dim(covid_survey)
# Creating a function to delete rows with a certain minimum number of NA's
delete.na <- function(DF, n = 0) {
DF[rowSums(is.na(DF)) <= n, ]
}
# Assuming 'covid_survey' is your data frame
covid_cleaned <- delete.na(covid_survey, 12)
# Relabeling survey responses, this doesn't work but U get the idea
covid_cleaned <- covid_cleaned %>%
mutate(exp_race = case_when(
exp_race == 1 ~ "American Indian / Alaskan native",
exp_race == 2 ~ "Asian",
exp_race == 3 ~ "Black / African American",
exp_race == 4 ~ "Native Hawaiian / Other Pacific Islander",
exp_race == 5 ~ "White",
TRUE ~ as.character(exp_race)  # Handling other cases
))
# Do not modify this chunk.
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
# Put all necessary libraries here
library(tidyverse)
library(ggplot2)
library(tidytuesdayR)
library(readr)
library(datapasta)
library(dplyr)
#using the libraries
covid_survey <- read_csv("C:/Users/agjjo/OneDrive/Documents/GitHub/math241/labs/lab04/data/covid-survey.csv")
#View(covid_survey)
dim(covid_survey)
# Creating a function to delete rows with a certain minimum number of NA's
delete.na <- function(DF, n = 0) {
DF[rowSums(is.na(DF)) <= n, ]
}
# Assuming 'covid_survey' is your data frame
covid_cleaned <- delete.na(covid_survey, 12)
# Relabeling survey responses, this doesn't work but U get the idea
covid_cleaned <- covid_cleaned %>%
mutate(exp_race = case_when(
exp_race == 1 ~ "American Indian / Alaskan native",
exp_race == 2 ~ "Asian",
exp_race == 3 ~ "Black / African American",
exp_race == 4 ~ "Native Hawaiian / Other Pacific Islander",
exp_race == 5 ~ "White",
TRUE ~ as.character(exp_race)  # Handling other cases
))
# Put all necessary libraries here
library(tidyverse)
library(ggplot2)
library(tidytuesdayR)
library(readr)
library(datapasta)
library(dplyr)
#using the libraries
covid_survey <- read_csv("C:/Users/agjjo/OneDrive/Documents/GitHub/math241/labs/lab04/data/covid-survey.csv")
View(covid_survey)
dim(covid_survey)
# Put all necessary libraries here
library(tidyverse)
library(ggplot2)
library(tidytuesdayR)
library(readr)
library(datapasta)
library(dplyr)
tinytex::install_tinytex()
#using the libraries
covid_survey <- read_csv("C:/Users/agjjo/OneDrive/Documents/GitHub/math241/labs/lab04/data/covid-survey.csv")
#View(covid_survey)
dim(covid_survey)
# Do not modify this chunk.
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
library(knitr)
library(knitr)
# Do not modify this chunk.
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
# Put all necessary libraries here
library(tidyverse)
# Do not modify this chunk.
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
# Put all necessary libraries here
library(tidyverse)
library(rvest)
library(httr)
library(rnoaa)
init::renv
renv::init()
# Do not modify this chunk.
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
# Put all necessary libraries here
library(tidyverse)
library(rvest)
library(httr)
library(rnoaa)
renv::status
# Do not modify this chunk.
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
library(ggplot2)
library(dplyr)
library(readr)
library(lubridate)
readr::read_csv("week18_dallas_animals.csv")%>%
head(n = 5)
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
#Load tidyverse
library(tidyverse)
library(mdsr)
install.packages(mdsr)
install.package(mdsr)
install(mdsr)
install.packages("mdsr")
#Load tidyverse
library(tidyverse)
library(mdsr)
library(stringr)
install.packages("stringr")
# Do not modify this chunk.
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
#install.packages("leaflet")
# Put all necessary libraries here
library(tidyverse)
library(leaflet)
library(tidycensus)
library(ggplot2)
library(dplyr)
library(readr)
library(lubridate)
library(tmap)
library(sf)
biketown_data <- bind_rows(readr::read_csv("https://s3.amazonaws.com/biketown-tripdata-public/2017_01.csv"),
readr::read_csv("https://s3.amazonaws.com/biketown-tripdata-public/2017_07.csv"),
readr::read_csv("https://s3.amazonaws.com/biketown-tripdata-public/2017_11.csv")) %>%
select(StartDate, StartTime, EndDate, EndTime, Distance_Miles,
BikeID, StartLatitude, StartLongitude)
# Convert StartDate column to standard date-time format
biketown_data <- biketown_data %>%
mutate(
StartDate = parse_date_time(StartDate, orders = "ymd")
)
# Now create the month variable
biketown_data <- biketown_data %>%
mutate(
month = month(StartDate)
)
biketown_data <- bind_rows(readr::read_csv("https://s3.amazonaws.com/biketown-tripdata-public/2017_01.csv"),
readr::read_csv("https://s3.amazonaws.com/biketown-tripdata-public/2017_07.csv"),
readr::read_csv("https://s3.amazonaws.com/biketown-tripdata-public/2017_11.csv")) %>%
select(StartDate, StartTime, EndDate, EndTime, Distance_Miles,
BikeID, StartLatitude, StartLongitude)
biketown_data <- bind_rows(readr::read_csv("https://s3.amazonaws.com/biketown-tripdata-public/2017_01.csv"),
readr::read_csv("https://s3.amazonaws.com/biketown-tripdata-public/2017_07.csv"),
readr::read_csv("https://s3.amazonaws.com/biketown-tripdata-public/2017_11.csv")) %>%
select(StartDate, StartTime, EndDate, EndTime, Distance_Miles,
BikeID, StartLatitude, StartLongitude)
# Convert StartDate column to standard date-time format
biketown_data <- biketown_data %>%
mutate(
StartDate = mdy(StartDate, orders = "ymd")
)
# Convert StartDate column to standard date-time format
biketown_data <- biketown_data %>%
mutate(
StartDate = mdy(StartDate)
)
glimpse(biketown_data)
# Now create the month variable
biketown_data <- biketown_data %>%
mutate(
month = month(StartDate)
)
biketown_data <- biketown_data %>%
mutate(
month = month(StartDate)
) %>%
mutate(
month = month(StartDate),
season = case_when(
month %in% c(12, 1, 2) ~ "Winter",
month %in% c(3, 4, 5) ~ "Spring",
month %in% c(6, 7, 8) ~ "Summer",
month %in% c(9, 10, 11) ~ "Fall"
)
)
api_key <- "5fe0ca3703f6190c4f956fd1f3addb987986d607"
api_key <- "5fe0ca3703f6190c4f956fd1f3addb987986d607"
#looking at variable reall quick
v21 <- load_variables(2021, "acs5", cache = TRUE)
View(v21)
#pulling county level data
or <- get_acs(geography = "county",
year = 2021,
variables = c(median_gross_rent = "B25064_001"),
state = "OR",
survey = "acs5",
output = "wide")
View(or)
#pulling county level data
or <- get_acs(geography = "county",
county = "multnomah",
year = 2021,
variables = c(median_gross_rent = "B25064_001"),
state = "OR",
survey = "acs5",
output = "wide")
#pulling county level data
or <- get_acs(geography = "county",
county = "multnomah",
year = 2021,
variables = c("B25064_001"),
state = "OR",
survey = "acs5",
output = "wide")
#pulling county level data
or <- get_acs(geography = "tract",
county = "multnomah",
year = 2021,
variables = c(median_gross_rent = "B25064_001"),
state = "OR",
survey = "acs5",
output = "wide")
#pulling county level data
or <- get_acs(geography = "county",
county = "multnomah",
year = 2021,
variables = c(median_gross_rent = "B25064_001"),
state = "OR",
survey = "acs5")
#pulling county level data
or <- get_acs(geography = "county",
county = "multnomah",
year = 2021,
variables = c(median_gross_rent = "B25064_001"),
state = "OR",
survey = "acs5")
#pulling tract level data
mult_tracts <- get_acs(geography = "tract",
county = "multnomah",
year = 2021,
variables = c(median_gross_rent = "B25064_001"),
state = "OR",
survey = "acs5")
View(mult_tracts)
#pulling block group level data
mult_tracts <- get_acs(geography = "block group",
county = "multnomah",
year = 2021,
variables = c(median_gross_rent = "B25064_001"),
state = "OR",
survey = "acs5")
#pulling tract level data
mult_tracts <- get_acs(geography = "tract",
county = "multnomah",
year = 2021,
variables = c(median_gross_rent = "B25064_001"),
state = "OR",
survey = "acs5")
#pulling block group level data
mult_blocks <- get_acs(geography = "block group",
county = "multnomah",
year = 2021,
variables = c(median_gross_rent = "B25064_001"),
state = "OR",
survey = "acs5")
View(mult_blocks)
#pulling county level data
mult_county <- get_acs(geography = "county",
county = "multnomah",
year = 2021,
variables = c(median_gross_rent = "B25064_001"),
state = "OR",
survey = "acs5")
#pulling tract level data
mult_tracts <- get_acs(geography = "tract",
county = "multnomah",
year = 2021,
variables = c(median_gross_rent = "B25064_001"),
state = "OR",
survey = "acs5")
#pulling block group level data
mult_blocks <- get_acs(geography = "block group",
county = "multnomah",
year = 2021,
variables = c(median_gross_rent = "B25064_001"),
state = "OR",
survey = "acs5")
View(mult_county)
ggplot() +
geom_sf(data = mult_county) +
coord(sf)
ggplot() +
geom_sf(data = mult_county) +
coord_sf()
#pulling county level data
mult_county <- get_acs(geography = "county",
county = "multnomah",
year = 2021,
variables = c(median_gross_rent = "B25064_001"),
geometry = TRUE,
state = "OR",
survey = "acs5")
ggplot(data = mult_county, aes(geometry = geometry, fill = estimate)) +
geom_sf() +
coord_sf()
#pulling county level data
mult_county <- get_acs(geography = "county",
county = "multnomah",
variables = c(median_gross_rent = "B25064_001"),
geometry = TRUE,
state = "OR",
survey = "acs5")
ggplot(data = mult_county, aes(geometry = geometry, fill = estimate)) +
geom_sf() +
coord_sf()
#pulling county level data
mult_county <- get_acs(geography = "county",
county = "multnomah",
year = 2021,
variables = c(median_gross_rent = "B25064_001"),
geometry = TRUE,
state = "OR")
#pulling county level data
mult_county <- get_acs(geography = "county",
county = "multnomah",
variables = c(median_gross_rent = "B25064_001"),
geometry = TRUE,
state = "OR")
#pulling county level data
mult_county <- get_acs(geography = "county",
county = "multnomah",
variables = c(median_gross_rent = "B25064_001"),
geometry = TRUE,
state = "OR",
cache_table = TRUE)
ggplot(data = mult_county, aes(geometry = geometry, fill = estimate)) +
geom_sf() +
coord_sf()
#pulling county level data
mult_county <- get_acs(geography = "county",
county = "multnomah",
variables = c(median_gross_rent = "B25064_001"),
geometry = TRUE,
state = "OR",
cache_table = TRUE)
#pulling tract level data
mult_tracts <- get_acs(geography = "tract",
county = "multnomah",
variables = c(median_gross_rent = "B25064_001"),
geometry = TRUE,
state = "OR",
cache_table = TRUE)
#pulling block group level data
mult_blocks <- get_acs(geography = "block group",
county = "multnomah",
variables = c(median_gross_rent = "B25064_001"),
geometry = TRUE,
state = "OR",
cache_table = TRUE)
#tract level map
ggplot(data = mult_tracts, aes(geometry = geometry, fill = estimate)) +
geom_sf() +
coord_sf()
#block-group level map
ggplot(data = mult_blocks, aes(geometry = geometry, fill = estimate)) +
geom_sf() +
coord_sf()
#tract level map
ggplot(data = mult_tracts, aes(geometry = geometry, fill = estimate)) +
geom_sf() +
coord_sf()
View(biketown_data)
